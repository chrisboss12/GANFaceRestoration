{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8df8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, UpSampling2D, Dense, Input, Flatten, Conv2DTranspose, BatchNormalization, Activation\n",
    "from keras import Model, Sequential\n",
    "from keras.initializers import RandomNormal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "from PIL import Image\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from numpy import zeros, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311a2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "# Define the downsample function for the generator model\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    # Weight initialization\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                               kernel_initializer=initializer, use_bias=False))\n",
    "  \n",
    "    # Apply batch normalization if required and add leaky ReLU activation function to the model\n",
    "    if apply_batchnorm:\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    # Return the model\n",
    "    return model\n",
    "\n",
    "# Define the upsample function for the generator model\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    # Weight initialization\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False))\n",
    "  \n",
    "    # Apply batch normalization if required and add ReLU activation function to the model\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # Apply dropout if required\n",
    "    if apply_dropout:\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    # Return the model\n",
    "    return model\n",
    "\n",
    "input = 128\n",
    "\n",
    "# Generator network\n",
    "def Generator(in_shape=(256,256,3)):\n",
    "    inputs = tf.keras.layers.Input(in_shape)\n",
    "    \n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False),  # (batch_size, 128, 128, 64)\n",
    "        downsample(128, 4),  # (batch_size, 64, 64, 128)\n",
    "        downsample(256, 4),  # (batch_size, 32, 32, 256)\n",
    "        downsample(512, 4),  # (batch_size, 16, 16, 512)\n",
    "        downsample(512, 4),  # (batch_size, 8, 8, 512)\n",
    "        downsample(512, 4),  # (batch_size, 4, 4, 512)\n",
    "        downsample(512, 4),  # (batch_size, 2, 2, 512)\n",
    "        downsample(512, 4),  # (batch_size, 1, 1, 512)\n",
    "    ]\n",
    "    \n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
    "        upsample(512, 4),  # (batch_size, 16, 16, 1024)\n",
    "        upsample(256, 4),  # (batch_size, 32, 32, 512)\n",
    "        upsample(128, 4),  # (batch_size, 64, 64, 256)\n",
    "        upsample(64, 4),  # (batch_size, 128, 128, 128)\n",
    "    ]\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh')  # (batch_size, 256, 256, 3)\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    \n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "        \n",
    "    skips = reversed(skips[:-1])\n",
    "    \n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "        \n",
    "    x = last(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "LAMBDA = 100\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Define the loss function for the generator model \n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    # Binary cross-entropy loss function for the generator model\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # Mean absolute error loss function for the generator model \n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    # Total generator loss = gan loss + (LAMBDA * l1 loss) \n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "    # Return the total generator loss, gan loss, and l1 loss\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08686764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 128, 128, 64  3072        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 64, 64, 128)  131584      ['sequential[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 32, 32, 256)  525312      ['sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 16, 16, 512)  2099200     ['sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 8, 8, 512)    4196352     ['sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 4, 4, 512)    4196352     ['sequential_4[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 2, 2, 512)    4196352     ['sequential_5[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 1, 1, 512)    4196352     ['sequential_6[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 2, 2, 512)    4196352     ['sequential_7[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2, 2, 1024)   0           ['sequential_8[0][0]',           \n",
      "                                                                  'sequential_6[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 4, 4, 512)    8390656     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 4, 4, 1024)   0           ['sequential_9[0][0]',           \n",
      "                                                                  'sequential_5[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_10 (Sequential)     (None, 8, 8, 512)    8390656     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 1024)   0           ['sequential_10[0][0]',          \n",
      "                                                                  'sequential_4[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_11 (Sequential)     (None, 16, 16, 512)  8390656     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 16, 16, 1024  0           ['sequential_11[0][0]',          \n",
      "                                )                                 'sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_12 (Sequential)     (None, 32, 32, 256)  4195328     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 512)  0           ['sequential_12[0][0]',          \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_13 (Sequential)     (None, 64, 64, 128)  1049088     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 256)  0           ['sequential_13[0][0]',          \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 128, 128, 64  262400      ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 128, 128, 12  0           ['sequential_14[0][0]',          \n",
      "                                8)                                'sequential[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 256, 256, 3)  6147       ['concatenate_6[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54,425,859\n",
      "Trainable params: 54,414,979\n",
      "Non-trainable params: 10,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen = Generator()\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ef74081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global discriminator model\n",
    "def Global_Discriminator(in_shape=(256, 256, 3)):\n",
    "    # Weight initialization\n",
    "    init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    # Define the input layer\n",
    "    inputs = tf.keras.layers.Input(in_shape)\n",
    "    \n",
    "    # Define the convolutional layers\n",
    "    conv1 = tf.keras.layers.Conv2D(32, 5, strides=2, padding='same', kernel_initializer=init)(inputs)\n",
    "    conv1 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    \n",
    "    conv2 = tf.keras.layers.Conv2D(64, 5, strides=2, padding='same', kernel_initializer=init)(conv1)\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv2)\n",
    "    \n",
    "    conv3 = tf.keras.layers.Conv2D(128, 5, strides=2, padding='same', kernel_initializer=init)(conv2)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv3)\n",
    "    \n",
    "    conv4 = tf.keras.layers.Conv2D(256, 5, strides=2, padding='same', kernel_initializer=init)(conv3)\n",
    "    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv4)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv2D(256, 5, strides=2, padding='same', kernel_initializer=init)(conv4)\n",
    "    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv4)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(conv4)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Define the discriminator model\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def Local_Discriminator(input_shape=(256, 256, 3)):\n",
    "    # Weight initialization\n",
    "    init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    # Define the input layer\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Define the convolutional layers\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', kernel_initializer=init)(inputs)\n",
    "    conv1 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    \n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, strides=2, padding='same', kernel_initializer=init)(conv1)\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv2)\n",
    "    \n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, strides=2, padding='same', kernel_initializer=init)(conv2)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv3)\n",
    "    \n",
    "    conv4 = tf.keras.layers.Conv2D(512, 3, strides=2, padding='same', kernel_initializer=init)(conv3)\n",
    "    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv4)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(conv4)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Define the discriminator model\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Define the PatchGAN discriminator model\n",
    "def PGAN_Discriminator(input_shape=(256, 256, 3)):\n",
    "    # Weight initialisation\n",
    "    initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    # Define the input layer\n",
    "    inp = tf.keras.layers.Input(shape=input_shape, name='input_image')\n",
    "    # Define the target layer\n",
    "    tar = tf.keras.layers.Input(shape=input_shape, name='target_image')\n",
    "\n",
    "    # Concatenate the input and target images\n",
    "    x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)\n",
    "\n",
    "    # Define the convolutional layers\n",
    "    down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n",
    "  \n",
    "    # Define the batch normalisation layer\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    # Define the leaky ReLU layer\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
    "\n",
    "    # Define the last convolutional layer\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
    "  \n",
    "    # Define the discriminator model\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05b569bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "430d780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 128, 128, 32)      2432      \n",
      "                                                                 \n",
      " leaky_re_lu_61 (LeakyReLU)  (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 64, 64, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 64, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_62 (LeakyReLU)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 32, 32, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 32, 32, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_63 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 16, 16, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 16, 16, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_64 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 8, 8, 256)         1638656   \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_65 (LeakyReLU)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               8389120   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,109,185\n",
      "Trainable params: 11,107,777\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " leaky_re_lu_66 (LeakyReLU)  (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " batch_normalization_75 (Bat  (None, 128, 128, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_67 (LeakyReLU)  (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 64, 64, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_68 (LeakyReLU)  (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 32, 32, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_69 (LeakyReLU)  (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 524288)            0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               268435968 \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,991,041\n",
      "Trainable params: 269,989,249\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " target_image (InputLayer)      [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 256, 256, 6)  0           ['input_image[0][0]',            \n",
      "                                                                  'target_image[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_51 (Sequential)     (None, 128, 128, 64  6144        ['concatenate_23[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " sequential_52 (Sequential)     (None, 64, 64, 128)  131584      ['sequential_51[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_53 (Sequential)     (None, 32, 32, 256)  525312      ['sequential_52[0][0]']          \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 34, 34, 256)  0          ['sequential_53[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 31, 31, 512)  2097152     ['zero_padding2d_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 31, 31, 512)  2048       ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " leaky_re_lu_73 (LeakyReLU)     (None, 31, 31, 512)  0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, 33, 33, 512)  0          ['leaky_re_lu_73[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 30, 30, 1)    8193        ['zero_padding2d_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,770,433\n",
      "Trainable params: 2,768,641\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc = Global_Discriminator()\n",
    "disc.summary()\n",
    "\n",
    "disc2 = Local_Discriminator()\n",
    "disc2.summary()\n",
    "\n",
    "disc3 = PGAN_Discriminator()\n",
    "disc3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a206e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_model.compile(optimizer=Adam(learning_rate=1e-4), loss=['mse'])\n",
    "\n",
    "g_model = Generator(in_shape=(256,256,3))\n",
    "d_model = Global_Discriminator(in_shape=(256,256,3))\n",
    "\n",
    "def define_gan(g_model, d_model, in_shape=(256,256,3)):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    \n",
    "    # define the source image\n",
    "    in_src = Input(shape=in_shape)\n",
    "    \n",
    "    # connect the source image to the generator input\n",
    "    gen_out = g_model(in_src)\n",
    "    \n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    dis_out = d_model(gen_out)\n",
    "    \n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model(in_src, [dis_out, gen_out])\n",
    "    \n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mse'], \n",
    "                  optimizer=opt, \n",
    "                  loss_weights=[1,100])\n",
    "    \n",
    "    return model\n",
    "\n",
    "gan_model = define_gan(g_model, d_model, in_shape=(256,256,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743c739",
   "metadata": {},
   "source": [
    "### Generate real/fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f37c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a batch of random samples, returns images and target\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    trainA = dataset\n",
    "    \n",
    "    # choose random instances\n",
    "    ix = np.random.randint(0, trainA.shape[0], n_samples)\n",
    "    \n",
    "    # retrieve selected images\n",
    "    X1 = trainA[ix]\n",
    "    \n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, 1))\n",
    "    \n",
    "    return X1, y, ix\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    \n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((len(X), 1))\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea41234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7413 images belonging to 22 classes.\n",
      "Found 7686 images belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'C:/Users/chris/2023-mcm-master/src/data/masked_images_split/train'\n",
    "#image_files = data_dir + '/**/*_masked.png'\n",
    "\n",
    "orig_data_dir = 'C:/Users/chris/2023-mcm-master/src/data/dataset_split/train'\n",
    "#orig_image_files = orig_data_dir + '/**/*.png'\n",
    "\n",
    "# Define the ImageDataGenerator for training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load and preprocess training data\n",
    "train_masked = train_datagen.flow_from_directory(\n",
    "    data_dir,  # Pass the directory path, not the file paths\n",
    "    target_size=(256, 256),  # Specify the target size of the images\n",
    "    batch_size=32,\n",
    "    class_mode='input',  # Use 'input' for input modeling\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load and preprocess training data from orig_data_dir\n",
    "train_orig = train_datagen.flow_from_directory(\n",
    "    orig_data_dir,  # Pass the directory path, not the file paths\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='input',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43d565e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom generator that yields both masked and original images\n",
    "def combined_generator(masked_generator, orig_generator):\n",
    "    while True:\n",
    "        masked_images, _ = masked_generator.next()\n",
    "        orig_images, _ = orig_generator.next()\n",
    "        yield masked_images, orig_images\n",
    "\n",
    "# Create the combined generator\n",
    "combined_train_generator = combined_generator(train_masked, train_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7855ba9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7594f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, dataset_real, dataset_damaged, n_epochs=100, n_batch=32,n_batch_test=10): \n",
    "    # unpack dataset\n",
    "    #trainA= image_names\n",
    "    trainA= dataset_real\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # manually enumerate epochs\n",
    "\n",
    "    dlossreal=[]\n",
    "    dlossfake=[]\n",
    "    glossbce=[]\n",
    "    glossmae=[]\n",
    "    steps=[]\n",
    "    for k in range(1,n_epochs+1):\n",
    "        for i in range(bat_per_epo):\n",
    "            # select a batch of real samples\n",
    "            #X_real, y_real ,damaged_images= generate_real_samples(image_names, n_batch)  \n",
    "            X_real, y_real ,image_index= generate_real_samples(dataset_real, n_batch)\n",
    "            # generate a batch of fake samples\n",
    "            #X_fake, y_fake = generate_fake_samples(g_model, damaged_images)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, dataset_damaged[image_index])\n",
    "            if (i==124):\n",
    "                plt.figure(figsize=(20, 6))\n",
    "                for m in range(5):\n",
    "                # Display original\n",
    "                    ax = plt.subplot(3, 5, m + 1)\n",
    "                    plt.imshow(X_fake[m][:,:,::-1])\n",
    "                    ax.get_xaxis().set_visible(False)\n",
    "                    ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "                    ax = plt.subplot(3, 5, m + 1 + 5)\n",
    "                    plt.imshow(X_real[m][:,:,::-1])\n",
    "                    ax.get_xaxis().set_visible(False)\n",
    "                    ax.get_yaxis().set_visible(False)\n",
    "                    \n",
    "                    ax = plt.subplot(3, 5, m + 1 + 10)\n",
    "                    plt.imshow(dataset_damaged[image_index][m][:,:,::-1])\n",
    "                    ax.get_xaxis().set_visible(False)\n",
    "                    ax.get_yaxis().set_visible(False)\n",
    "                    \n",
    "                plt.show() \n",
    "        \n",
    "                # update discriminator for real samples\n",
    "               # d_model.trainable = True\n",
    "            d_loss_real = d_model.train_on_batch(X_real, y_real)\n",
    "            # update discriminator for generated samples\n",
    "            d_loss_fake = d_model.train_on_batch(X_fake, y_fake)\n",
    "            # update the generator\n",
    "            #gloss_all,g_loss_BCE,g_loss_mae= gan_model.train_on_batch(damaged_images, [y_real, X_real])\n",
    "            gloss_all,g_loss_BCE,g_loss_mae = gan_model.train_on_batch(dataset_damaged[image_index], [y_real, X_real])\n",
    "            # summarize performance\n",
    "            if(i==124):\n",
    "              #print('>%d, d_real[%.5f] d_fake[%.5f] g_BCE[%.5f] g_mae[%.5f]' % (i+1, d_loss_real, d_loss_fake, g_loss_BCE,g_loss_mae))\n",
    "              print('epochs[%d],batch[%d], d_real[%.5f] d_fake[%.5f] g_BCE[%.5f] g_mae[%.5f]' % (k,i+1, d_loss_real, d_loss_fake, g_loss_BCE,g_loss_mae))\n",
    "            dlossreal.append(d_loss_real)\n",
    "            dlossfake.append(d_loss_fake)\n",
    "            glossbce.append(g_loss_BCE)\n",
    "            glossmae.append(g_loss_mae)\n",
    "            #steps.append(i)\n",
    "            steps.append(k*i)\n",
    "    plt.plot(steps,dlossreal)\n",
    "    plt.plot(steps,dlossfake)\n",
    "    plt.title('Discriminator loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('batches')\n",
    "    plt.legend(['Discriminator real loss', 'Discriminator fake loss'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(steps,glossbce)\n",
    "    plt.plot(steps,glossmae)\n",
    "    plt.title('Generator loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('batches')\n",
    "    plt.legend(['GAN BCE train loss', 'Generator MAE train loss'], loc='upper right')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78abeed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_4\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None, None, None) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m train_cgan \u001b[38;5;241m=\u001b[39m custom_data_generator(train_masked, train_orig)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Train the model using fit\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mgan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_cgan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mprint('Start of training')\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03mdef train(d_model, g_model, gan_model, dataset_real, dataset_damaged, n_epochs=100, n_batch=32, n_batch_test=10):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m    plt.show()\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\chris\\anaconda3\\envs\\snowflakes\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_4\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None, None, None) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of steps per epoch\n",
    "steps_per_epoch = min(len(train_masked), len(train_orig))\n",
    "\n",
    "#train_x = pickle.load(open(\"C:/Users/chris/2023-mcm-master/src/data/dataset_split/train_images.pkl\", \"rb\"))\n",
    "#train_Y = pickle.load(open(\"C:/Users/chris/2023-mcm-master/src/data/dataset_split/orig_train_images.pkl\", \"rb\"))\n",
    "\n",
    "# Create the custom data generator\n",
    "train_cgan = custom_data_generator(train_masked, train_orig)\n",
    "\n",
    "# Train the model using fit\n",
    "history = gan_model.fit(\n",
    "    train_cgan,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=50,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "print('Start of training')\n",
    "def train(d_model, g_model, gan_model, dataset_real, dataset_damaged, n_epochs=100, n_batch=32, n_batch_test=10):\n",
    "    # Convert dataset_real to a NumPy array\n",
    "    dataset_real = np.array(dataset_real)\n",
    "\n",
    "gan_model.save('C:/Users/chris/2023-mcm-master/src/data/model_results/faces_inpaint_gan.h5',overwrite=True)\n",
    "g_model.save('C:/Users/chris/2023-mcm-master/src/data/model_results/faces_inpaint_g.h5',overwrite=True)\n",
    "d_model.save('C:/Users/chris/2023-mcm-master/src/data/model_results/faces_inpaint_d.h5',overwrite=True)\n",
    "\n",
    "for m in range(0,7):\n",
    "    pyplot.figure(figsize=(20, 6))\n",
    "    \n",
    "    for i in range(5):\n",
    "        # Display original\n",
    "        ax = pyplot.subplot(3, 5, i + 1)\n",
    "        pyplot.imshow(damaged_images[i+5*m][:,:,::-1])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        # Display reconstruction\n",
    "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "        plt.imshow(pred[i+5*m])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        # Display ground truth\n",
    "        ax = pyplot.subplot(3, 5, i + 1 + 10)\n",
    "        pyplot.imshow(x_train[i+5*m][:,:,::-1])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed590b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b4175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
